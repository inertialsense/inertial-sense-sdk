<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.4"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>SDK: Multi-threaded applications and asynchronous I/O</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectlogo"><img alt="Logo" src="IS_LOGO_BLACK_F03_email_signature.png"/></td>
  <td id="projectalign">
   <div id="projectname">SDK<span id="projectnumber">&#160;Release 1.9.0</span>
   </div>
   <div id="projectbrief">Communications, logger, and bootloader libraries.</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.4 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search",'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div><div class="header">
  <div class="headertitle"><div class="title">Multi-threaded applications and asynchronous I/O </div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p >libusb is a thread-safe library, but extra considerations must be applied to applications which interact with libusb from multiple threads.</p>
<p >The underlying issue that must be addressed is that all libusb I/O revolves around monitoring file descriptors through the poll()/select() system calls. This is directly exposed at the <a class="el" href="group__libusb__asyncio.html">asynchronous interface</a> but it is important to note that the <a class="el" href="group__libusb__syncio.html">synchronous interface</a> is implemented on top of the asynchronous interface, therefore the same considerations apply.</p>
<p >The issue is that if two or more threads are concurrently calling poll() or select() on libusb's file descriptors then only one of those threads will be woken up when an event arrives. The others will be completely oblivious that anything has happened.</p>
<p >Consider the following pseudo-code, which submits an asynchronous transfer then waits for its completion. This style is one way you could implement a synchronous interface on top of the asynchronous interface (and libusb does something similar, albeit more advanced due to the complications explained on this page).</p>
<div class="fragment"><div class="line"><span class="keywordtype">void</span> cb(<span class="keyword">struct</span> <a class="code hl_struct" href="structlibusb__transfer.html">libusb_transfer</a> *transfer)</div>
<div class="line">{</div>
<div class="line">    <span class="keywordtype">int</span> *completed = transfer-&gt;<a class="code hl_variable" href="structlibusb__transfer.html#ab75ab3e7185f08e07a1ae858a35ebb7b">user_data</a>;</div>
<div class="line">     *completed = 1;</div>
<div class="line">}</div>
<div class="line"> </div>
<div class="line"><span class="keywordtype">void</span> myfunc() {</div>
<div class="line">    <span class="keyword">struct </span><a class="code hl_struct" href="structlibusb__transfer.html">libusb_transfer</a> *transfer;</div>
<div class="line">    <span class="keywordtype">unsigned</span> <span class="keywordtype">char</span> <a class="code hl_variable" href="structlibusb__transfer.html#a7fa594567e074191ce8f28b5fb4a3bea">buffer</a>[<a class="code hl_define" href="libusb_8h.html#af39dc5e7622e8559df7f1d3da5478717">LIBUSB_CONTROL_SETUP_SIZE</a>] __attribute__ ((aligned (2)));</div>
<div class="line">    <span class="keywordtype">int</span> completed = 0;</div>
<div class="line"> </div>
<div class="line">    transfer = <a class="code hl_function" href="group__libusb__asyncio.html#gace1ff6c04a3cc6d3366fdb352fb5d04f">libusb_alloc_transfer</a>(0);</div>
<div class="line">    libusb_fill_control_setup(<a class="code hl_variable" href="structlibusb__transfer.html#a7fa594567e074191ce8f28b5fb4a3bea">buffer</a>,</div>
<div class="line">        <a class="code hl_enumvalue" href="group__libusb__misc.html#gga0b0933ae70744726cde11254c39fac91a1585f40d2a73c752a5f60688612c1345">LIBUSB_REQUEST_TYPE_VENDOR</a> | <a class="code hl_enumvalue" href="group__libusb__desc.html#gga86c880af878493aa8f805c2aba654b8ba940484c16d44bdfc6eccc2de7a9ffcb2">LIBUSB_ENDPOINT_OUT</a>, 0x04, 0x01, 0, 0);</div>
<div class="line">    libusb_fill_control_transfer(transfer, dev, <a class="code hl_variable" href="structlibusb__transfer.html#a7fa594567e074191ce8f28b5fb4a3bea">buffer</a>, cb, &amp;completed, 1000);</div>
<div class="line">    <a class="code hl_function" href="group__libusb__asyncio.html#ga01cdfe1a27027a5f438b17cf2dcede2b">libusb_submit_transfer</a>(transfer);</div>
<div class="line"> </div>
<div class="line">    <span class="keywordflow">while</span> (!completed) {</div>
<div class="line">        poll(libusb file descriptors, 120*1000);</div>
<div class="line">        <span class="keywordflow">if</span> (poll indicates activity)</div>
<div class="line">            <a class="code hl_function" href="group__libusb__poll.html#gae74724dd975e6eb49bb8e93640c126dd">libusb_handle_events_timeout</a>(ctx, &amp;zero_tv);</div>
<div class="line">    }</div>
<div class="line">    printf(<span class="stringliteral">&quot;completed!&quot;</span>);</div>
<div class="line">    <span class="comment">// other code here</span></div>
<div class="line">}</div>
<div class="ttc" id="agroup__libusb__asyncio_html_ga01cdfe1a27027a5f438b17cf2dcede2b"><div class="ttname"><a href="group__libusb__asyncio.html#ga01cdfe1a27027a5f438b17cf2dcede2b">libusb_submit_transfer</a></div><div class="ttdeci">int API_EXPORTED libusb_submit_transfer(struct libusb_transfer *transfer)</div><div class="ttdef"><b>Definition:</b> <a href="io_8c_source.html#l01490">io.c:1490</a></div></div>
<div class="ttc" id="agroup__libusb__asyncio_html_gace1ff6c04a3cc6d3366fdb352fb5d04f"><div class="ttname"><a href="group__libusb__asyncio.html#gace1ff6c04a3cc6d3366fdb352fb5d04f">libusb_alloc_transfer</a></div><div class="ttdeci">DEFAULT_VISIBILITY struct libusb_transfer *LIBUSB_CALL libusb_alloc_transfer(int iso_packets)</div><div class="ttdef"><b>Definition:</b> <a href="io_8c_source.html#l01285">io.c:1285</a></div></div>
<div class="ttc" id="agroup__libusb__desc_html_gga86c880af878493aa8f805c2aba654b8ba940484c16d44bdfc6eccc2de7a9ffcb2"><div class="ttname"><a href="group__libusb__desc.html#gga86c880af878493aa8f805c2aba654b8ba940484c16d44bdfc6eccc2de7a9ffcb2">LIBUSB_ENDPOINT_OUT</a></div><div class="ttdeci">@ LIBUSB_ENDPOINT_OUT</div><div class="ttdef"><b>Definition:</b> <a href="libusb_8h_source.html#l00325">libusb.h:325</a></div></div>
<div class="ttc" id="agroup__libusb__misc_html_gga0b0933ae70744726cde11254c39fac91a1585f40d2a73c752a5f60688612c1345"><div class="ttname"><a href="group__libusb__misc.html#gga0b0933ae70744726cde11254c39fac91a1585f40d2a73c752a5f60688612c1345">LIBUSB_REQUEST_TYPE_VENDOR</a></div><div class="ttdeci">@ LIBUSB_REQUEST_TYPE_VENDOR</div><div class="ttdef"><b>Definition:</b> <a href="libusb_8h_source.html#l00411">libusb.h:411</a></div></div>
<div class="ttc" id="agroup__libusb__poll_html_gae74724dd975e6eb49bb8e93640c126dd"><div class="ttname"><a href="group__libusb__poll.html#gae74724dd975e6eb49bb8e93640c126dd">libusb_handle_events_timeout</a></div><div class="ttdeci">int API_EXPORTED libusb_handle_events_timeout(libusb_context *ctx, struct timeval *tv)</div><div class="ttdef"><b>Definition:</b> <a href="io_8c_source.html#l02411">io.c:2411</a></div></div>
<div class="ttc" id="alibusb_8h_html_af39dc5e7622e8559df7f1d3da5478717"><div class="ttname"><a href="libusb_8h.html#af39dc5e7622e8559df7f1d3da5478717">LIBUSB_CONTROL_SETUP_SIZE</a></div><div class="ttdeci">#define LIBUSB_CONTROL_SETUP_SIZE</div><div class="ttdef"><b>Definition:</b> <a href="libusb_8h_source.html#l00945">libusb.h:945</a></div></div>
<div class="ttc" id="astructlibusb__transfer_html"><div class="ttname"><a href="structlibusb__transfer.html">libusb_transfer</a></div><div class="ttdef"><b>Definition:</b> <a href="libusb_8h_source.html#l01229">libusb.h:1229</a></div></div>
<div class="ttc" id="astructlibusb__transfer_html_a7fa594567e074191ce8f28b5fb4a3bea"><div class="ttname"><a href="structlibusb__transfer.html#a7fa594567e074191ce8f28b5fb4a3bea">libusb_transfer::buffer</a></div><div class="ttdeci">unsigned char * buffer</div><div class="ttdef"><b>Definition:</b> <a href="libusb_8h_source.html#l01280">libusb.h:1280</a></div></div>
<div class="ttc" id="astructlibusb__transfer_html_ab75ab3e7185f08e07a1ae858a35ebb7b"><div class="ttname"><a href="structlibusb__transfer.html#ab75ab3e7185f08e07a1ae858a35ebb7b">libusb_transfer::user_data</a></div><div class="ttdeci">void * user_data</div><div class="ttdef"><b>Definition:</b> <a href="libusb_8h_source.html#l01277">libusb.h:1277</a></div></div>
</div><!-- fragment --><p >Here we are <em>serializing</em> completion of an asynchronous event against a condition - the condition being completion of a specific transfer. The poll() loop has a long timeout to minimize CPU usage during situations when nothing is happening (it could reasonably be unlimited).</p>
<p >If this is the only thread that is polling libusb's file descriptors, there is no problem: there is no danger that another thread will swallow up the event that we are interested in. On the other hand, if there is another thread polling the same descriptors, there is a chance that it will receive the event that we were interested in. In this situation, <code>myfunc()</code> will only realise that the transfer has completed on the next iteration of the loop, <em>up to 120 seconds later.</em> Clearly a two-minute delay is undesirable, and don't even think about using short timeouts to circumvent this issue!</p>
<p >The solution here is to ensure that no two threads are ever polling the file descriptors at the same time. A naive implementation of this would impact the capabilities of the library, so libusb offers the scheme documented below to ensure no loss of functionality.</p>
<p >Before we go any further, it is worth mentioning that all libusb-wrapped event handling procedures fully adhere to the scheme documented below. This includes <a class="el" href="group__libusb__poll.html#gae51897021354eae052a382e814a587ba">libusb_handle_events()</a> and its variants, and all the synchronous I/O functions - libusb hides this headache from you.</p>
<h1><a class="anchor" id="Using"></a>
libusb_handle_events() from multiple threads</h1>
<p >Even when only using <a class="el" href="group__libusb__poll.html#gae51897021354eae052a382e814a587ba">libusb_handle_events()</a> and synchronous I/O functions, you can still have a race condition. You might be tempted to solve the above with <a class="el" href="group__libusb__poll.html#gae51897021354eae052a382e814a587ba">libusb_handle_events()</a> like so:</p>
<div class="fragment"><div class="line"><a class="code hl_function" href="group__libusb__asyncio.html#ga01cdfe1a27027a5f438b17cf2dcede2b">libusb_submit_transfer</a>(transfer);</div>
<div class="line"> </div>
<div class="line"><span class="keywordflow">while</span> (!completed) {</div>
<div class="line">    <a class="code hl_function" href="group__libusb__poll.html#gae51897021354eae052a382e814a587ba">libusb_handle_events</a>(ctx);</div>
<div class="line">}</div>
<div class="line">printf(<span class="stringliteral">&quot;completed!&quot;</span>);</div>
<div class="ttc" id="agroup__libusb__poll_html_gae51897021354eae052a382e814a587ba"><div class="ttname"><a href="group__libusb__poll.html#gae51897021354eae052a382e814a587ba">libusb_handle_events</a></div><div class="ttdeci">int API_EXPORTED libusb_handle_events(libusb_context *ctx)</div><div class="ttdef"><b>Definition:</b> <a href="io_8c_source.html#l02431">io.c:2431</a></div></div>
</div><!-- fragment --><p >This however has a race between the checking of completed and <a class="el" href="group__libusb__poll.html#gae51897021354eae052a382e814a587ba">libusb_handle_events()</a> acquiring the events lock, so another thread could have completed the transfer, resulting in this thread hanging until either a timeout or another event occurs. See also commit 6696512aade99bb15d6792af90ae329af270eba6 which fixes this in the synchronous API implementation of libusb.</p>
<p >Fixing this race requires checking the variable completed only after taking the event lock, which defeats the concept of just calling <a class="el" href="group__libusb__poll.html#gae51897021354eae052a382e814a587ba">libusb_handle_events()</a> without worrying about locking. This is why libusb-1.0.9 introduces the new <a class="el" href="group__libusb__poll.html#ga45948958630109e2969221f845f58fbd">libusb_handle_events_timeout_completed()</a> and <a class="el" href="group__libusb__poll.html#ga166cee6b958a10ec2c43055c97505d38">libusb_handle_events_completed()</a> functions, which handles doing the completion check for you after they have acquired the lock:</p>
<div class="fragment"><div class="line"><a class="code hl_function" href="group__libusb__asyncio.html#ga01cdfe1a27027a5f438b17cf2dcede2b">libusb_submit_transfer</a>(transfer);</div>
<div class="line"> </div>
<div class="line"><span class="keywordflow">while</span> (!completed) {</div>
<div class="line">    <a class="code hl_function" href="group__libusb__poll.html#ga166cee6b958a10ec2c43055c97505d38">libusb_handle_events_completed</a>(ctx, &amp;completed);</div>
<div class="line">}</div>
<div class="line">printf(<span class="stringliteral">&quot;completed!&quot;</span>);</div>
<div class="ttc" id="agroup__libusb__poll_html_ga166cee6b958a10ec2c43055c97505d38"><div class="ttname"><a href="group__libusb__poll.html#ga166cee6b958a10ec2c43055c97505d38">libusb_handle_events_completed</a></div><div class="ttdeci">int API_EXPORTED libusb_handle_events_completed(libusb_context *ctx, int *completed)</div><div class="ttdef"><b>Definition:</b> <a href="io_8c_source.html#l02453">io.c:2453</a></div></div>
</div><!-- fragment --><p >This nicely fixes the race in our example. Note that if all you want to do is submit a single transfer and wait for its completion, then using one of the synchronous I/O functions is much easier.</p>
<dl class="section note"><dt>Note</dt><dd>The <code>completed</code> variable must be modified while holding the event lock, otherwise a race condition can still exist. It is simplest to do so from within the transfer callback as shown above.</dd></dl>
<h1><a class="anchor" id="eventlock"></a>
The events lock</h1>
<p >The problem is when we consider the fact that libusb exposes file descriptors to allow for you to integrate asynchronous USB I/O into existing main loops, effectively allowing you to do some work behind libusb's back. If you do take libusb's file descriptors and pass them to poll()/select() yourself, you need to be aware of the associated issues.</p>
<p >The first concept to be introduced is the events lock. The events lock is used to serialize threads that want to handle events, such that only one thread is handling events at any one time.</p>
<p >You must take the events lock before polling libusb file descriptors, using <a class="el" href="group__libusb__poll.html#ga3fe966580b283e1efc91c7e11bae0c89">libusb_lock_events()</a>. You must release the lock as soon as you have aborted your poll()/select() loop, using <a class="el" href="group__libusb__poll.html#gadb8f5d4fb12b340f40b0bed841fe5fa0">libusb_unlock_events()</a>.</p>
<h1><a class="anchor" id="threadwait"></a>
Letting other threads do the work for you</h1>
<p >Although the events lock is a critical part of the solution, it is not enough on it's own. You might wonder if the following is sufficient... </p><div class="fragment"><div class="line"><a class="code hl_function" href="group__libusb__poll.html#ga3fe966580b283e1efc91c7e11bae0c89">libusb_lock_events</a>(ctx);</div>
<div class="line"><span class="keywordflow">while</span> (!completed) {</div>
<div class="line">    poll(libusb file descriptors, 120*1000);</div>
<div class="line">    <span class="keywordflow">if</span> (poll indicates activity)</div>
<div class="line">        <a class="code hl_function" href="group__libusb__poll.html#gae74724dd975e6eb49bb8e93640c126dd">libusb_handle_events_timeout</a>(ctx, &amp;zero_tv);</div>
<div class="line">}</div>
<div class="line"><a class="code hl_function" href="group__libusb__poll.html#gadb8f5d4fb12b340f40b0bed841fe5fa0">libusb_unlock_events</a>(ctx);</div>
<div class="ttc" id="agroup__libusb__poll_html_ga3fe966580b283e1efc91c7e11bae0c89"><div class="ttname"><a href="group__libusb__poll.html#ga3fe966580b283e1efc91c7e11bae0c89">libusb_lock_events</a></div><div class="ttdeci">void API_EXPORTED libusb_lock_events(libusb_context *ctx)</div><div class="ttdef"><b>Definition:</b> <a href="io_8c_source.html#l01832">io.c:1832</a></div></div>
<div class="ttc" id="agroup__libusb__poll_html_gadb8f5d4fb12b340f40b0bed841fe5fa0"><div class="ttname"><a href="group__libusb__poll.html#gadb8f5d4fb12b340f40b0bed841fe5fa0">libusb_unlock_events</a></div><div class="ttdeci">void API_EXPORTED libusb_unlock_events(libusb_context *ctx)</div><div class="ttdef"><b>Definition:</b> <a href="io_8c_source.html#l01847">io.c:1847</a></div></div>
</div><!-- fragment --><p> ...and the answer is that it is not. This is because the transfer in the code shown above may take a long time (say 30 seconds) to complete, and the lock is not released until the transfer is completed.</p>
<p >Another thread with similar code that wants to do event handling may be working with a transfer that completes after a few milliseconds. Despite having such a quick completion time, the other thread cannot check that status of its transfer until the code above has finished (30 seconds later) due to contention on the lock.</p>
<p >To solve this, libusb offers you a mechanism to determine when another thread is handling events. It also offers a mechanism to block your thread until the event handling thread has completed an event (and this mechanism does not involve polling of file descriptors).</p>
<p >After determining that another thread is currently handling events, you obtain the <em>event waiters</em> lock using <a class="el" href="group__libusb__poll.html#ga42414148fd511c5af8cc65cc0daf504a">libusb_lock_event_waiters()</a>. You then re-check that some other thread is still handling events, and if so, you call <a class="el" href="group__libusb__poll.html#ga24bcd0e269101fdbd00ecd38602bc2c1">libusb_wait_for_event()</a>.</p>
<p ><a class="el" href="group__libusb__poll.html#ga24bcd0e269101fdbd00ecd38602bc2c1">libusb_wait_for_event()</a> puts your application to sleep until an event occurs, or until a thread releases the events lock. When either of these things happen, your thread is woken up, and should re-check the condition it was waiting on. It should also re-check that another thread is handling events, and if not, it should start handling events itself.</p>
<p >This looks like the following, as pseudo-code: </p><div class="fragment"><div class="line">retry:</div>
<div class="line"><span class="keywordflow">if</span> (<a class="code hl_function" href="group__libusb__poll.html#ga81cc7c2bc30407c59b7e734c7550f8b2">libusb_try_lock_events</a>(ctx) == 0) {</div>
<div class="line">    <span class="comment">// we obtained the event lock: do our own event handling</span></div>
<div class="line">    <span class="keywordflow">while</span> (!completed) {</div>
<div class="line">        <span class="keywordflow">if</span> (!<a class="code hl_function" href="group__libusb__poll.html#gaff8a999713883242aebec53fd8fda288">libusb_event_handling_ok</a>(ctx)) {</div>
<div class="line">            <a class="code hl_function" href="group__libusb__poll.html#gadb8f5d4fb12b340f40b0bed841fe5fa0">libusb_unlock_events</a>(ctx);</div>
<div class="line">            <span class="keywordflow">goto</span> retry;</div>
<div class="line">        }</div>
<div class="line">        poll(libusb file descriptors, 120*1000);</div>
<div class="line">        <span class="keywordflow">if</span> (poll indicates activity)</div>
<div class="line">            <a class="code hl_function" href="group__libusb__poll.html#ga06ee3999a05c494d0aad084d052e5774">libusb_handle_events_locked</a>(ctx, 0);</div>
<div class="line">    }</div>
<div class="line">    <a class="code hl_function" href="group__libusb__poll.html#gadb8f5d4fb12b340f40b0bed841fe5fa0">libusb_unlock_events</a>(ctx);</div>
<div class="line">} <span class="keywordflow">else</span> {</div>
<div class="line">    <span class="comment">// another thread is doing event handling. wait for it to signal us that</span></div>
<div class="line">    <span class="comment">// an event has completed</span></div>
<div class="line">    <a class="code hl_function" href="group__libusb__poll.html#ga42414148fd511c5af8cc65cc0daf504a">libusb_lock_event_waiters</a>(ctx);</div>
<div class="line"> </div>
<div class="line">    <span class="keywordflow">while</span> (!completed) {</div>
<div class="line">        <span class="comment">// now that we have the event waiters lock, double check that another</span></div>
<div class="line">        <span class="comment">// thread is still handling events for us. (it may have ceased handling</span></div>
<div class="line">        <span class="comment">// events in the time it took us to reach this point)</span></div>
<div class="line">        <span class="keywordflow">if</span> (!<a class="code hl_function" href="group__libusb__poll.html#ga448517e64d5b326944432ab773b8262f">libusb_event_handler_active</a>(ctx)) {</div>
<div class="line">            <span class="comment">// whoever was handling events is no longer doing so, try again</span></div>
<div class="line">            <a class="code hl_function" href="group__libusb__poll.html#gacbf0f55ba01600dee3c3d78dc27f495d">libusb_unlock_event_waiters</a>(ctx);</div>
<div class="line">            <span class="keywordflow">goto</span> retry;</div>
<div class="line">        }</div>
<div class="line"> </div>
<div class="line">        <a class="code hl_function" href="group__libusb__poll.html#ga24bcd0e269101fdbd00ecd38602bc2c1">libusb_wait_for_event</a>(ctx, NULL);</div>
<div class="line">    }</div>
<div class="line">    <a class="code hl_function" href="group__libusb__poll.html#gacbf0f55ba01600dee3c3d78dc27f495d">libusb_unlock_event_waiters</a>(ctx);</div>
<div class="line">}</div>
<div class="line">printf(<span class="stringliteral">&quot;completed!\n&quot;</span>);</div>
<div class="ttc" id="agroup__libusb__poll_html_ga06ee3999a05c494d0aad084d052e5774"><div class="ttname"><a href="group__libusb__poll.html#ga06ee3999a05c494d0aad084d052e5774">libusb_handle_events_locked</a></div><div class="ttdeci">int API_EXPORTED libusb_handle_events_locked(libusb_context *ctx, struct timeval *tv)</div><div class="ttdef"><b>Definition:</b> <a href="io_8c_source.html#l02481">io.c:2481</a></div></div>
<div class="ttc" id="agroup__libusb__poll_html_ga24bcd0e269101fdbd00ecd38602bc2c1"><div class="ttname"><a href="group__libusb__poll.html#ga24bcd0e269101fdbd00ecd38602bc2c1">libusb_wait_for_event</a></div><div class="ttdeci">int API_EXPORTED libusb_wait_for_event(libusb_context *ctx, struct timeval *tv)</div><div class="ttdef"><b>Definition:</b> <a href="io_8c_source.html#l02019">io.c:2019</a></div></div>
<div class="ttc" id="agroup__libusb__poll_html_ga42414148fd511c5af8cc65cc0daf504a"><div class="ttname"><a href="group__libusb__poll.html#ga42414148fd511c5af8cc65cc0daf504a">libusb_lock_event_waiters</a></div><div class="ttdeci">void API_EXPORTED libusb_lock_event_waiters(libusb_context *ctx)</div><div class="ttdef"><b>Definition:</b> <a href="io_8c_source.html#l01976">io.c:1976</a></div></div>
<div class="ttc" id="agroup__libusb__poll_html_ga448517e64d5b326944432ab773b8262f"><div class="ttname"><a href="group__libusb__poll.html#ga448517e64d5b326944432ab773b8262f">libusb_event_handler_active</a></div><div class="ttdeci">int API_EXPORTED libusb_event_handler_active(libusb_context *ctx)</div><div class="ttdef"><b>Definition:</b> <a href="io_8c_source.html#l01911">io.c:1911</a></div></div>
<div class="ttc" id="agroup__libusb__poll_html_ga81cc7c2bc30407c59b7e734c7550f8b2"><div class="ttname"><a href="group__libusb__poll.html#ga81cc7c2bc30407c59b7e734c7550f8b2">libusb_try_lock_events</a></div><div class="ttdeci">int API_EXPORTED libusb_try_lock_events(libusb_context *ctx)</div><div class="ttdef"><b>Definition:</b> <a href="io_8c_source.html#l01789">io.c:1789</a></div></div>
<div class="ttc" id="agroup__libusb__poll_html_gacbf0f55ba01600dee3c3d78dc27f495d"><div class="ttname"><a href="group__libusb__poll.html#gacbf0f55ba01600dee3c3d78dc27f495d">libusb_unlock_event_waiters</a></div><div class="ttdeci">void API_EXPORTED libusb_unlock_event_waiters(libusb_context *ctx)</div><div class="ttdef"><b>Definition:</b> <a href="io_8c_source.html#l01987">io.c:1987</a></div></div>
<div class="ttc" id="agroup__libusb__poll_html_gaff8a999713883242aebec53fd8fda288"><div class="ttname"><a href="group__libusb__poll.html#gaff8a999713883242aebec53fd8fda288">libusb_event_handling_ok</a></div><div class="ttdeci">int API_EXPORTED libusb_event_handling_ok(libusb_context *ctx)</div><div class="ttdef"><b>Definition:</b> <a href="io_8c_source.html#l01882">io.c:1882</a></div></div>
</div><!-- fragment --><p >A naive look at the above code may suggest that this can only support one event waiter (hence a total of 2 competing threads, the other doing event handling), because the event waiter seems to have taken the event waiters lock while waiting for an event. However, the system does support multiple event waiters, because <a class="el" href="group__libusb__poll.html#ga24bcd0e269101fdbd00ecd38602bc2c1">libusb_wait_for_event()</a> actually drops the lock while waiting, and reacquires it before continuing.</p>
<p >We have now implemented code which can dynamically handle situations where nobody is handling events (so we should do it ourselves), and it can also handle situations where another thread is doing event handling (so we can piggyback onto them). It is also equipped to handle a combination of the two, for example, another thread is doing event handling, but for whatever reason it stops doing so before our condition is met, so we take over the event handling.</p>
<p >Four functions were introduced in the above pseudo-code. Their importance should be apparent from the code shown above.</p><ol type="1">
<li><a class="el" href="group__libusb__poll.html#ga81cc7c2bc30407c59b7e734c7550f8b2">libusb_try_lock_events()</a> is a non-blocking function which attempts to acquire the events lock but returns a failure code if it is contended.</li>
<li><a class="el" href="group__libusb__poll.html#gaff8a999713883242aebec53fd8fda288">libusb_event_handling_ok()</a> checks that libusb is still happy for your thread to be performing event handling. Sometimes, libusb needs to interrupt the event handler, and this is how you can check if you have been interrupted. If this function returns 0, the correct behaviour is for you to give up the event handling lock, and then to repeat the cycle. The following <a class="el" href="group__libusb__poll.html#ga81cc7c2bc30407c59b7e734c7550f8b2">libusb_try_lock_events()</a> will fail, so you will become an events waiter. For more information on this, read <a class="el" href="libusb_mtasync.html#fullstory">The full story</a> below.</li>
<li><a class="el" href="group__libusb__poll.html#ga06ee3999a05c494d0aad084d052e5774">libusb_handle_events_locked()</a> is a variant of <a class="el" href="group__libusb__poll.html#gae74724dd975e6eb49bb8e93640c126dd">libusb_handle_events_timeout()</a> that you can call while holding the events lock. <a class="el" href="group__libusb__poll.html#gae74724dd975e6eb49bb8e93640c126dd">libusb_handle_events_timeout()</a> itself implements similar logic to the above, so be sure not to call it when you are "working behind libusb's back", as is the case here.</li>
<li><a class="el" href="group__libusb__poll.html#ga448517e64d5b326944432ab773b8262f">libusb_event_handler_active()</a> determines if someone is currently holding the events lock</li>
</ol>
<p >You might be wondering why there is no function to wake up all threads blocked on <a class="el" href="group__libusb__poll.html#ga24bcd0e269101fdbd00ecd38602bc2c1">libusb_wait_for_event()</a>. This is because libusb can do this internally: it will wake up all such threads when someone calls <a class="el" href="group__libusb__poll.html#gadb8f5d4fb12b340f40b0bed841fe5fa0">libusb_unlock_events()</a> or when a transfer completes (at the point after its callback has returned).</p>
<h2><a class="anchor" id="fullstory"></a>
The full story</h2>
<p >The above explanation should be enough to get you going, but if you're really thinking through the issues then you may be left with some more questions regarding libusb's internals. If you're curious, read on, and if not, skip to the next section to avoid confusing yourself!</p>
<p >The immediate question that may spring to mind is: what if one thread modifies the set of file descriptors that need to be polled while another thread is doing event handling?</p>
<p >There are 2 situations in which this may happen.</p><ol type="1">
<li><a class="el" href="group__libusb__dev.html#gaae48f83e4b9652964ce501d914dd505e">libusb_open()</a> will add another file descriptor to the poll set, therefore it is desirable to interrupt the event handler so that it restarts, picking up the new descriptor.</li>
<li><a class="el" href="group__libusb__dev.html#ga6c0534023632fdc669c1dde47f259f2f">libusb_close()</a> will remove a file descriptor from the poll set. There are all kinds of race conditions that could arise here, so it is important that nobody is doing event handling at this time.</li>
</ol>
<p >libusb handles these issues internally, so application developers do not have to stop their event handlers while opening/closing devices. Here's how it works, focusing on the <a class="el" href="group__libusb__dev.html#ga6c0534023632fdc669c1dde47f259f2f">libusb_close()</a> situation first:</p>
<ol type="1">
<li>During initialization, libusb opens an internal pipe, and it adds the read end of this pipe to the set of file descriptors to be polled.</li>
<li>During <a class="el" href="group__libusb__dev.html#ga6c0534023632fdc669c1dde47f259f2f">libusb_close()</a>, libusb writes some dummy data on this event pipe. This immediately interrupts the event handler. libusb also records internally that it is trying to interrupt event handlers for this high-priority event.</li>
<li>At this point, some of the functions described above start behaving differently:<ul>
<li><a class="el" href="group__libusb__poll.html#gaff8a999713883242aebec53fd8fda288">libusb_event_handling_ok()</a> starts returning 1, indicating that it is NOT OK for event handling to continue.</li>
<li><a class="el" href="group__libusb__poll.html#ga81cc7c2bc30407c59b7e734c7550f8b2">libusb_try_lock_events()</a> starts returning 1, indicating that another thread holds the event handling lock, even if the lock is uncontended.</li>
<li><a class="el" href="group__libusb__poll.html#ga448517e64d5b326944432ab773b8262f">libusb_event_handler_active()</a> starts returning 1, indicating that another thread is doing event handling, even if that is not true.</li>
</ul>
</li>
<li>The above changes in behaviour result in the event handler stopping and giving up the events lock very quickly, giving the high-priority <a class="el" href="group__libusb__dev.html#ga6c0534023632fdc669c1dde47f259f2f">libusb_close()</a> operation a "free ride" to acquire the events lock. All threads that are competing to do event handling become event waiters.</li>
<li>With the events lock held inside <a class="el" href="group__libusb__dev.html#ga6c0534023632fdc669c1dde47f259f2f">libusb_close()</a>, libusb can safely remove a file descriptor from the poll set, in the safety of knowledge that nobody is polling those descriptors or trying to access the poll set.</li>
<li>After obtaining the events lock, the close operation completes very quickly (usually a matter of milliseconds) and then immediately releases the events lock.</li>
<li>At the same time, the behaviour of <a class="el" href="group__libusb__poll.html#gaff8a999713883242aebec53fd8fda288">libusb_event_handling_ok()</a> and friends reverts to the original, documented behaviour.</li>
<li>The release of the events lock causes the threads that are waiting for events to be woken up and to start competing to become event handlers again. One of them will succeed; it will then re-obtain the list of poll descriptors, and USB I/O will then continue as normal.</li>
</ol>
<p ><a class="el" href="group__libusb__dev.html#gaae48f83e4b9652964ce501d914dd505e">libusb_open()</a> is similar, and is actually a more simplistic case. Upon a call to <a class="el" href="group__libusb__dev.html#gaae48f83e4b9652964ce501d914dd505e">libusb_open()</a>:</p>
<ol type="1">
<li>The device is opened and a file descriptor is added to the poll set.</li>
<li>libusb sends some dummy data on the event pipe, and records that it is trying to modify the poll descriptor set.</li>
<li>The event handler is interrupted, and the same behaviour change as for <a class="el" href="group__libusb__dev.html#ga6c0534023632fdc669c1dde47f259f2f">libusb_close()</a> takes effect, causing all event handling threads to become event waiters.</li>
<li>The <a class="el" href="group__libusb__dev.html#gaae48f83e4b9652964ce501d914dd505e">libusb_open()</a> implementation takes its free ride to the events lock.</li>
<li>Happy that it has successfully paused the events handler, <a class="el" href="group__libusb__dev.html#gaae48f83e4b9652964ce501d914dd505e">libusb_open()</a> releases the events lock.</li>
<li>The event waiter threads are all woken up and compete to become event handlers again. The one that succeeds will obtain the list of poll descriptors again, which will include the addition of the new device.</li>
</ol>
<h2><a class="anchor" id="concl"></a>
Closing remarks</h2>
<p >The above may seem a little complicated, but hopefully I have made it clear why such complications are necessary. Also, do not forget that this only applies to applications that take libusb's file descriptors and integrate them into their own polling loops.</p>
<p >You may decide that it is OK for your multi-threaded application to ignore some of the rules and locks detailed above, because you don't think that two threads can ever be polling the descriptors at the same time. If that is the case, then that's good news for you because you don't have to worry. But be careful here; remember that the synchronous I/O functions do event handling internally. If you have one thread doing event handling in a loop (without implementing the rules and locking semantics documented above) and another trying to send a synchronous USB transfer, you will end up with two threads monitoring the same descriptors, and the above-described undesirable behaviour occurring. The solution is for your polling thread to play by the rules; the synchronous I/O functions do so, and this will result in them getting along in perfect harmony.</p>
<p >If you do have a dedicated thread doing event handling, it is perfectly legal for it to take the event handling lock for long periods of time. Any synchronous I/O functions you call from other threads will transparently fall back to the "event waiters" mechanism detailed above. The only consideration that your event handling thread must apply is the one related to <a class="el" href="group__libusb__poll.html#gaff8a999713883242aebec53fd8fda288">libusb_event_handling_ok()</a>: you must call this before every poll(), and give up the events lock if instructed. </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.4
</small></address>
</body>
</html>
